{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859dbc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cfarhomes/psando/miniconda3/envs/seg/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "\n",
    "from model.pspnet import PSPNet, DeepLabV3\n",
    "from util import dataset, transform, config\n",
    "from PIL import Image\n",
    "# from util.util import AverageMeter, intersectionAndUnion, check_makedirs, colorize\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cf2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "\n",
    "def show(imgs, figsize=(10,10), save_filename=None):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False, figsize=figsize)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = transforms.functional.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    if save_filename:\n",
    "        fix.savefig(save_filename, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10dae3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/vulcanscratch/psando/semseg_experiments/train_advprop_psp/model/train_epoch_50.pth'\n",
      "=> loaded checkpoint '/vulcanscratch/psando/semseg_experiments/train_advprop_psp/model/train_epoch_50.pth'\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "from model.mixbn import MixBatchNorm2d\n",
    "\n",
    "args = config.load_cfg_from_cfg_file('config/paper/voc2012/voc2012_pspnet50.yaml')\n",
    "\n",
    "base_save_path = os.path.join('/vulcanscratch/psando/semseg_experiments', 'train_advprop_psp')\n",
    "args.model_path = os.path.join(os.path.join(base_save_path, 'model'), 'train_epoch_50.pth')\n",
    "args.save_path = os.path.join(base_save_path, 'result')\n",
    "\n",
    "batch_norm = MixBatchNorm2d\n",
    "\n",
    "model = torch.nn.DataParallel(PSPNet(layers=args.layers, classes=args.classes, zoom_factor=args.zoom_factor, pretrained=False, BatchNorm=batch_norm))\n",
    "model = model.cuda()\n",
    "cudnn.benchmark = True\n",
    "if os.path.isfile(args.model_path):\n",
    "    print(\"=> loading checkpoint '{}'\".format(args.model_path))\n",
    "    checkpoint = torch.load(args.model_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "    print(\"=> loaded checkpoint '{}'\".format(args.model_path))\n",
    "else:\n",
    "    raise RuntimeError(\"=> no checkpoint found at '{}'\".format(args.model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556a7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "055f8948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixBatchNorm2d(\n",
       "  64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "  (aux_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.layer0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "110f5d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.9941e-01, 2.4484e-01, 1.6613e-06, 2.1719e-06, 5.3578e-05, 1.7431e-01,\n",
       "        4.3489e-01, 2.2361e-08, 2.5743e-01, 1.5029e-01, 1.8021e-01, 4.5049e-01,\n",
       "        9.0471e-02, 8.0701e-02, 1.1520e-01, 8.5650e-07, 2.4974e-01, 4.3030e-01,\n",
       "        7.0187e-06, 5.9870e-02, 1.2643e-06, 1.8235e-01, 1.6881e-01, 2.5544e-01,\n",
       "        2.4502e-01, 3.5655e-08, 1.6903e-01, 2.7256e-01, 2.0809e-01, 2.5900e-01,\n",
       "        2.1319e-08, 9.4099e-02, 1.7858e-01, 2.2511e-01, 1.7098e-01, 6.1804e-07,\n",
       "        7.0976e-06, 1.5933e-01, 1.4840e-01, 1.5984e-01, 2.3096e-01, 8.0616e-06,\n",
       "        3.3085e-01, 1.6960e-01, 1.6717e-01, 4.2818e-05, 1.1963e-01, 2.9062e-07,\n",
       "        2.9910e-01, 1.2965e-01, 2.2730e-01, 6.2015e-06, 7.0814e-09, 1.4086e-01,\n",
       "        1.5904e-01, 1.5913e-01, 2.8527e-01, 1.9741e-01, 1.5335e-04, 2.0480e-01,\n",
       "        2.1538e-01, 2.4562e-01, 2.2961e-01, 8.8388e-08], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.layer0[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "524cce27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.layer0[1].aux_bn.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced7b18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
